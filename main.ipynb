{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNBq5xTbNrMfn60gUHBwl03",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nerudxlf/getting_quartiles_scopus/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEqh80rOZIcC"
      },
      "source": [
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from collections import Counter\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m73lFdjbZQWU"
      },
      "source": [
        "def source_title_update(data: object) -> object:\n",
        "  \"\"\"\n",
        "  Функция для получения ключа из столбца Source Title\n",
        "  Ключ состоит из букв верхнего регистра и не содержит других символов\n",
        "  param: data(DataFrame): Выгрузка из Scopus\n",
        "  return: data(DataFrame): Выгрузки из Scopus + столбец KEY\n",
        "  \"\"\"\n",
        "  data_list = data[\"Source Title\"].to_list()\n",
        "  result_list = []\n",
        "  for elem in data_list:\n",
        "    if isinstance(elem, float):\n",
        "      result_list.append(\"not\")\n",
        "      continue\n",
        "    elem = elem.upper()\n",
        "    elem = re.sub(\"[^A-Za-z0-9]\", \"\", elem)\n",
        "    result_list.append(elem)\n",
        "  data[\"KEY\"] = result_list\n",
        "  return data\n",
        "\n",
        "\n",
        "def get_result(s: object, data: object) -> object:\n",
        "  \"\"\"\n",
        "  Функция соединяет 2 DataFrame по столбцу KEY\n",
        "  Позволяет получить нужные публикации по квартилям\n",
        "  param: s(DataFrame): Таблица с определенным квартилем\n",
        "         data(DataFrame): Выгрузка из Scopus\n",
        "  return: result_s_df(DataFrame): Таблица с публикациями по квартилям\n",
        "  \"\"\"\n",
        "  result_s_df = pd.merge(left=s, right=data, left_on=\"KEY\", right_on=\"KEY\")\n",
        "  result_s_df.drop(['Unnamed: 0', 'Source Title_y'], axis=1, inplace=True)\n",
        "  result_s_df = result_s_df.drop_duplicates(subset=[\"Title\"])\n",
        "  result_s_df.rename(columns={\"Source Title_x\": \"Source Title\"}, inplace=True)\n",
        "  return result_s_df\n",
        "\n",
        "\n",
        "def get_n(data: object) -> object:\n",
        "  \"\"\"\n",
        "  Функция считает число аффилиаций у каждого автора\n",
        "  В цикле по столбцу Authors with affiliations находятся авторы\n",
        "  Если автор из ОмГТУ, то автор добавляется в список авторов ОмГТУ\n",
        "  и в общий список авторов\n",
        "  Ксли автор не из ОмГТУ, то автор добавляется в общий список авторов\n",
        "  Далее считается сколько раз в общем списке встречается каждый автор\n",
        "  Далее по формуле total = total + 1/count, находится доля ОмГТУ в каждой статье\n",
        "  (где count количество вхождений автора в общий список авторов)\n",
        "  Затем считается общая доля ОмГТУ во всех статьях \n",
        "\n",
        "  param data(DataFrame): таблица из статей с каким-либо квартилем\n",
        "  return data(DataFrame): возвращает таблицу(Статья|Доля ОмГТУ)\n",
        "  \"\"\"\n",
        "  data_list = data[\"Authors with affiliations\"].to_list()\n",
        "  affiliations_list = data[\"Affiliations\"].to_list()\n",
        "  i = 0\n",
        "  n_list = []\n",
        "  for elem in data_list:\n",
        "    affiliations_split = affiliations_list[i].split(\"; \")\n",
        "    elem_split = elem.split(\"; \")\n",
        "    omstu_list = []\n",
        "    total = 0\n",
        "    all_list = []\n",
        "    for item in elem_split:\n",
        "      item_split = item.split(' ')\n",
        "      for affil in affiliations_split:\n",
        "        if item.find(affil) != -1:\n",
        "          if item.find(\"Omsk State Technical University\") != -1:\n",
        "            author = re.sub(r'[^A-Za-z]', '', item_split[0])\n",
        "            omstu_list.append(author)\n",
        "            all_list.append(author)\n",
        "          else:\n",
        "            author = re.sub(r'[^A-Za-z]', '', item_split[0])\n",
        "            all_list.append(author)\n",
        "    all_dict = dict(Counter(all_list))\n",
        "    n2 = len(all_dict.keys())\n",
        "    for item in omstu_list:\n",
        "      total += 1 / all_dict[item]\n",
        "    n = total / n2\n",
        "    n_list.append(n)\n",
        "    i += 1\n",
        "  data[\"N\"] = n_list\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fonWe7UZ7Pi"
      },
      "source": [
        "scopus_df = pd.read_excel(\"scopus2019.xlsx\")\n",
        "s1_df = pd.read_excel(\"s1.xlsx\")\n",
        "s2_df = pd.read_excel(\"s2.xlsx\")\n",
        "s3_df = pd.read_excel(\"s3.xlsx\")\n",
        "s4_df = pd.read_excel(\"s4.xlsx\")\n",
        "\n",
        "scopus_df_update = scopus_df.filter(\n",
        "        [\"Authors\", \"Title\", \"Source Title\", \"Affiliations\", \"Authors with affiliations\"])\n",
        "scopus_df_and_key = source_title_update(scopus_df_update)\n",
        "s1_df_and_key = source_title_update(s1_df)\n",
        "s2_df_and_key = source_title_update(s2_df)\n",
        "s3_df_and_key = source_title_update(s3_df)\n",
        "s4_df_and_key = source_title_update(s4_df)\n",
        "\n",
        "result_s1_df = get_result(s1_df_and_key, scopus_df_and_key)\n",
        "result_s1_df = get_n(result_s1_df)\n",
        "\n",
        "result_s2_df = get_result(s2_df_and_key, scopus_df_and_key)\n",
        "result_s2_df = get_n(result_s2_df)\n",
        "\n",
        "result_s3_df = get_result(s3_df_and_key, scopus_df_and_key)\n",
        "result_s3_df = get_n(result_s3_df)\n",
        "\n",
        "result_s4_df = get_result(s4_df_and_key, scopus_df_and_key)\n",
        "result_s4_df = get_n(result_s4_df)\n",
        "\n",
        "con_data = pd.concat([result_s1_df, result_s2_df, result_s3_df, result_s4_df])\n",
        "con_data.drop([\"KEY\", \"N\"], axis=1, inplace=True)\n",
        "scopus_df_update.drop([\"KEY\"], axis=1, inplace=True)\n",
        "result_s_none_df = pd.concat([scopus_df_update, con_data]).drop_duplicates(keep=False)\n",
        "result_s_none_df = result_s_none_df.drop_duplicates(subset=[\"Title\"], keep=False)\n",
        "result_s_none_df = get_n(result_s_none_df)\n",
        "\n",
        "result_s1_df.to_excel(\"s1_result.xlsx\", index=False)\n",
        "result_s2_df.to_excel(\"s2_result.xlsx\", index=False)\n",
        "result_s3_df.to_excel(\"s3_result.xlsx\", index=False)\n",
        "result_s4_df.to_excel(\"s4_result.xlsx\", index=False)\n",
        "result_s_none_df.to_excel(\"s_none_result.xlsx\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}